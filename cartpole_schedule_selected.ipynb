{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from gymhelpers import ExperimentsManager\n",
    "import scipy.io as scipyio\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem: CartPole-v1, Temp: 1, Strategy: sparsemax, Backup: bellman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-10-24 02:33:45,958] Making new env: CartPole-v1\n",
      "[2017-10-24 02:33:46,110] Making new env: CartPole-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EXECUTING EXPERIMENT 0 OF 3 IN ENVIRONMENT CartPole-v1.\n",
      "Minimum average reward reached. Stop training and exploration.\n",
      "Final mean reward, averaged over 1 experiment: 496.707070707 (std = 0.0).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "plot_utils.py:83: RuntimeWarning: invalid value encountered in divide\n",
      "  factor = higher_border / mu\n",
      "plot_utils.py:84: RuntimeWarning: divide by zero encountered in divide\n",
      "  lower_border = np.clip(lower_border, mu / factor, mu)\n",
      "[2017-10-24 02:43:49,045] Making new env: CartPole-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average episode duration: 601.386295 ms\n",
      "\n",
      "EXECUTING EXPERIMENT 1 OF 3 IN ENVIRONMENT CartPole-v1.\n",
      "Minimum average reward reached. Stop training and exploration.\n",
      "Final mean reward, averaged over 2 experiments: 498.353535354 (std = 1.64646464646).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-10-24 02:51:18,409] Making new env: CartPole-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average episode duration: 447.649049 ms\n",
      "\n",
      "EXECUTING EXPERIMENT 2 OF 3 IN ENVIRONMENT CartPole-v1.\n",
      "Minimum average reward reached. Stop training and exploration.\n",
      "Final mean reward, averaged over 3 experiments: 498.902356902 (std = 1.55230175533).\n",
      "Average episode duration: 410.463378 ms\n",
      "Average final reward: 498.91 (std=10.81).\n",
      "\n",
      "The 100-episode moving average reached 472 after 749 episodes.\n",
      "Problem: CartPole-v1, Temp: 1, Strategy: softmax, Backup: bellman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-10-24 02:58:11,889] Making new env: CartPole-v1\n",
      "[2017-10-24 02:58:11,892] Making new env: CartPole-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EXECUTING EXPERIMENT 0 OF 3 IN ENVIRONMENT CartPole-v1.\n",
      "Minimum average reward reached. Stop training and exploration.\n",
      "Final mean reward, averaged over 1 experiment: 500.0 (std = 0.0).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-10-24 03:02:44,815] Making new env: CartPole-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average episode duration: 271.576119 ms\n",
      "\n",
      "EXECUTING EXPERIMENT 1 OF 3 IN ENVIRONMENT CartPole-v1.\n",
      "Final mean reward, averaged over 2 experiments: 446.333333333 (std = 53.6666666667).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-10-24 03:12:47,372] Making new env: CartPole-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average episode duration: 601.204857 ms\n",
      "\n",
      "EXECUTING EXPERIMENT 2 OF 3 IN ENVIRONMENT CartPole-v1.\n",
      "Minimum average reward reached. Stop training and exploration.\n",
      "Final mean reward, averaged over 3 experiments: 464.222222222 (std = 50.5974185649).\n",
      "Average episode duration: 353.834876 ms\n",
      "Average final reward: 464.58 (std=50.47).\n",
      "\n",
      "The 100-episode moving average reached 472 after 569 episodes.\n",
      "Problem: CartPole-v1, Temp: 1, Strategy: epsilon, Backup: bellman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-10-24 03:18:44,192] Making new env: CartPole-v1\n",
      "[2017-10-24 03:18:44,194] Making new env: CartPole-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EXECUTING EXPERIMENT 0 OF 3 IN ENVIRONMENT CartPole-v1.\n",
      "Minimum average reward reached. Stop training and exploration.\n",
      "Final mean reward, averaged over 1 experiment: 500.0 (std = 0.0).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-10-24 03:23:54,934] Making new env: CartPole-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average episode duration: 309.439833 ms\n",
      "\n",
      "EXECUTING EXPERIMENT 1 OF 3 IN ENVIRONMENT CartPole-v1.\n",
      "Minimum average reward reached. Stop training and exploration.\n",
      "Final mean reward, averaged over 2 experiments: 500.0 (std = 0.0).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-10-24 03:29:05,416] Making new env: CartPole-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average episode duration: 308.944424 ms\n",
      "\n",
      "EXECUTING EXPERIMENT 2 OF 3 IN ENVIRONMENT CartPole-v1.\n",
      "Final mean reward, averaged over 3 experiments: 450.242424242 (std = 70.3678384672).\n",
      "Average episode duration: 434.074509 ms\n",
      "Average final reward: 449.78 (std=36.97).\n",
      "\n",
      "The 100-episode moving average reached 472 after 652 episodes.\n",
      "CartPole-v1 is finished and is saved\n"
     ]
    }
   ],
   "source": [
    "strategies = [\"sparsemax\",\"softmax\",\"epsilon\"]\n",
    "backuprules = [\"bellman\",\"bellman\",\"bellman\"]\n",
    "temperatures = [1,1,1]\n",
    "temperatures_name = [\"high\",\"high\",\"high\"]\n",
    "\n",
    "env_name = \"CartPole-v1\"\n",
    "min_avg_rwd = 472\n",
    "stop_training_min_avg_rwd = 468\n",
    "layers_size = [256, 256]\n",
    "n_ep = 1000\n",
    "n_exps = 3\n",
    "\n",
    "gym_stats_dir_prefix = os.path.join('Gym_stats', env_name)\n",
    "figures_dir = 'Figures'\n",
    "api_key = '###'\n",
    "alg_id = '###'\n",
    "\n",
    "data = defaultdict(lambda : defaultdict(lambda : defaultdict(lambda : None)))\n",
    "for temperature, temperature_name, strategy, backuprule in zip(temperatures, temperatures_name, strategies, backuprules):\n",
    "            gym_stats_dir_prefix = os.path.join('Gym_stats', \n",
    "                                                env_name+'/'+str(strategy)+'/'+str(backuprule)+'/'+str(temperature_name))\n",
    "            print(\"Problem: {}, Temp: {}, Strategy: {}, Backup: {}\".format(env_name,temperature,strategy,backuprule))\n",
    "            expsman = ExperimentsManager(env_name=env_name, agent_value_function_hidden_layers_size=layers_size,\n",
    "                                  figures_dir=figures_dir, discount=0.99, decay_eps=0.95, eps_min=1E-4, learning_rate=3E-4,\n",
    "                                  decay_lr=True, max_step=10000, replay_memory_max_size=10000, ep_verbose=True,\n",
    "                                  exp_verbose=False, learning_rate_end=3E-5, batch_size=128, upload_last_exp=False, double_dqn=True, dueling=False,\n",
    "                                  target_params_update_period_steps=50, replay_period_steps=4, min_avg_rwd=min_avg_rwd,\n",
    "                                  per_proportional_prioritization=True, per_apply_importance_sampling=True, per_alpha=0.2,\n",
    "                                  per_beta0=0.4,\n",
    "                                  results_dir_prefix=gym_stats_dir_prefix, gym_api_key=api_key, gym_algorithm_id=alg_id,\n",
    "                                  strategy=strategy,backuprule=backuprule,\n",
    "                                  temperature_max=100, decay_temperature=0.95, temperature_min=1)\n",
    "            _, _, Rwd_per_ep_v, Loss_per_ep_v = expsman.run_experiments(n_exps=n_exps, n_ep=n_ep, stop_training_min_avg_rwd=stop_training_min_avg_rwd, plot_results=False)\n",
    "            data[temperature_name][strategy][backuprule] = {\"reward_list\":Rwd_per_ep_v,\"loss_list\":Loss_per_ep_v}\n",
    "\n",
    "scipyio.savemat(env_name+\"_selected_100_1.mat\", data)\n",
    "print(\"{} is finished and is saved\".format(env_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
